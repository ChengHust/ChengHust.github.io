<!DOCTYPE HTML>
<html lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-160123878-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-160123878-1');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-153593080-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-153593080-1');
  </script>

  <title>Zhichao Lu</title>

  <meta name="author" content="Zhichao Lu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="format-detection" content="telephone=no">

  <!-- Icon -->
  <link rel="apple-touch-icon" sizes="180x180" href="icons/id_clipart.jpeg">
  <link rel="icon" type="image/png" sizes="32x32" href="icons/id_clipart.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="icons/id_clipart.jpeg">
  <link rel="manifest" href="icons/site.webmanifest">


  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
    integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

  <!-- Custom Styles -->
  <link rel="stylesheet" type="text/css" href="index.css">


</head>

<body>

  <div class="container content">
    <div class="row">
      <div class="col-12 col-md-10 offset-md-1">

        <nav class="navbar navbar-expand-md navbar-light sticky-top" style="background-color: white;">

          <a href="#" class="navbar-brand">
            <name id="top">Zhichao Lu (陆智超)</name>
          </a>

          <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbarCollapse">
            <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse" id="navbarCollapse">
            <div class="navbar-nav navbar-custom">
              <a href="#" class="nav-item nav-link">Home</a>
              <a href="index_publication.html" class="nav-item nav-link">Publications</a>
              <a href="index_vitae.html" class="nav-item nav-link">Vitae</a>
            </div>
          </div>

        </nav>

        <div class="container">

          <div class="row" style="padding: 15px 0px;">

            <div class="col-12 col-md-4 order-md-12 align-self-center">
              <a href="images/zhichao_lu_msu_circle.png">
                <img style="width: 200px; height: 200px; padding: 15px; margin: 10px 0px;" alt="profile photo"
                  src="images/zhichao_lu_msu_circle.png" class="mx-auto d-block">
              </a>
            </div>

            <div class="col-12 col-md-8 order-md-1">

              <p>
                Post-doc Research Fellow</br>
                Southern University of Science and Technology (SUSTech) </br>
                luzhichaocn [at] gmail.com</br>

                </br>

                Zhichao Lu is currently a post-doctoral research fellow with the Dept. of
                Computer Science and Engineering at the Southern University of Science
                and Technology, Shenzhen, China. He received the B.Sc. and Ph.D degrees
                in Electrical and Computer Engineering from Michigan State University, USA, in 2014 and 2020.
                He was a member in the
                <a href="https://coin-lab.org/" target='_blank'>COIN Laboratory</a>,
                under the supervision of Prof.
                <a href="https://egr.msu.edu/~kdeb" target='_blank'>Kalyanmoy Deb</a>.
                He collaborate closely with Prof. <a href="http://hal.cse.msu.edu/" target='_blank'>
                Vishnu Boddeti</a>, Prof. <a href="https://www.egr.msu.edu/~goodman/" target='_blank'>
                Erik Goodman</a>, and Prof. <a href="https://www.cse.msu.edu/~banzhafw/" target='_blank'>
                Wolfgang Banzhaf</a>.
                </br>
                </br>
                His main research interest is <em>Computational Intelligence</em> based learning, modeling,
                and optimization, notably evolutionary multi-objective optimization, automated
                machine learning, and in particular evolutionary neural architecture search.
                </br>

              </p>


              <div>
                <p style="text-align:center">
                  <a href="assets/cv/zhichao_lu_cv_20210823.pdf" rel="noopener noreferrer" target="_blank">CV</a> /
                  <a href="assets/cv/zhichao_lu_cv_cn_20210823.pdf" rel="noopener noreferrer" target="_blank">简历</a> /
                  <a href="https://scholar.google.com/citations?user=mtzAY2wAAAAJ&hl=en" rel="noopener noreferrer"
                    target="_blank">Google Scholar</a> /
                  <a href="https://github.com/mikelzc1990" rel="noopener noreferrer" target="_blank">Github </a> /
                  <a href="https://www.linkedin.com/in/zhichao-lu-728037b4/" rel="noopener noreferrer" target="_blank">LinkedIn </a>
                </p>

              </div>

            </div>

          </div>


          <div class="row heading">
            <div class="col-12">
              <heading id="news">Recent News</heading>
              <hr>
            </div>
          </div>

          <div class="col-12 col-md-0 order-md-12 align-self-center">
            <ul>
              <li> <b>08/2021:</b> Thanks National Natural Science Foundation of China
                to fund our surrogate-assisted evolutionary neural architecture search project
                (国家自然科学基金青年科学基金项目)! </li>
              <li> <b>07/2021:</b> Two papers accepted to ICCV '21! Congratulations to
                <a href="http://www.shihuahuang.cn/" target='_blank'>Shihua Huang</a>,
                <a href="https://scholar.google.com/citations?user=TqY98koAAAAJ&hl=en"
                   target='_blank'>Teng Wang</a> and all collaborators!</li>
              <li> <b>06/2021:</b> Our team are the <span style="color:mediumvioletred; font-weight: bold;">
                Runner Up Winner</span> of the <a
                      href="http://activity-net.org/challenges/2021/tasks/anet_localization.html"
                      target='_blank'>2021 CVPR ActivityNet Event Dense-Captioning Challenge</a>.
                Congratulations to <a href="https://scholar.google.com/citations?user=TqY98koAAAAJ&hl=en"
                                      target='_blank'>Teng Wang</a> and
                <a href="https://faculty.sustech.edu.cn/?p=98950&tagid=fengzheng&cat=2&iscss=1&snapid=1&orderby=date&lang=en"
                   target='_blank'>Zhu Liu</a> for leading the project! <a
                        href="https://youtu.be/5zHz44qdXv0?t=1348"
                        target='_blank'>Oral presentation at CVPR 21 Workshop</a>.</li>
              <li> <b>06/2021:</b> Thanks China Postdoctoral Science Foundation to
                fund our evolutionary multi-objective neural architecture search project
                (中国博士后科学基金面上资助项目)! </li>
              <li> <b>02/2021:</b> Our paper titled "<a
                      href="https://ieeexplore.ieee.org/abstract/document/9352206"
                      target='_blank'>A New Many-Objective Evolutionary Algorithm Based on Generalized Pareto Dominance</a>"
                is accepted to <a href="https://ieeexplore.ieee.org/abstract/document/9352206"
                                  target='_blank'>IEEE T-CYB</a>! Congratulations to <a
                        href="https://scholar.google.com/citations?user=ua4p6_gAAAAJ&hl=en"
                        target='_blank'>Shuwei Zhu</a> for leading the paper!</li>
              <li> <b>01/2021:</b> Our paper titled "<a
                      href="http://hal.cse.msu.edu/assets/pdfs/papers/2021-tpami-neural-architecture-transfer.pdf"
                      target='_blank'>Neural Architecture Transfer</a>"
                is accepted to <a href="https://ieeexplore.ieee.org/document/9328602"
                                  target='_blank'>IEEE T-PAMI</a>!</li>
              <li> <b>09/2020:</b> Our paper titled "<a
                      href="http://hal.cse.msu.edu/assets/pdfs/papers/2020-tevc-nsganetv1.pdf"
                      target='_blank'>Multiobjective Evolutionary Design of Deep Convolutional Neural Networks for
                Image Classification</a>"
                is accepted to <a href="https://ieeexplore.ieee.org/abstract/document/9201169"
                                  target='_blank'>IEEE T-EVC</a>!</li>
              <li> <b>07/2020:</b> <a
                      href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460035.pdf"
                      target='_blank'>NSGANetV2</a>
                is accepted as <span style="color:mediumvioletred; font-weight: bold;">
                  Oral (top 2%)</span> at ECCV '20!</li>
              <li> <b>06/2020:</b> <a
                      href="https://arxiv.org/pdf/1810.03522.pdf"
                      target='_blank'>NSGA-Net</a> is invited to
                <a href="https://www.ijcai.org/proceedings/2020/659"
                   target='_blank'>IJCAI '20 as an extended abstract</a>.</li>
              <li> <b>04/2020:</b> <a
                      href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_MUXConv_Information_Multiplexing_in_Convolutional_Neural_Networks_CVPR_2020_paper.pdf"
                      target='_blank'>MUXConv</a>
                is accepted to CVPR '20!</li>
              <li> <b>07/2019:</b> <a
                      href="https://arxiv.org/pdf/1810.03522.pdf"
                      target='_blank'>NSGA-Net</a> won the <span style="color:mediumvioletred; font-weight: bold;">
                      Best Paper Award</span> at <a
                      href="https://gecco-2019.sigevo.org/index.html/Best+Paper+Awards"
                      target='_blank'>GECCO '19 (Evolutionary Machine Learning Track)</a>.</li>
            </ul>
          </div>


          <div class="row heading">
            <div class="col-12">
              <heading id="news">Selected Research</heading>
              <hr>
            </div>
          </div>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

<!--            <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">-->
            <tr onmouseout="fapn_stop()" onmouseover="fapn_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                  <img src='images/2021-iccv-fapn.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2108.07058">
                  <papertitle>FaPN: Feature-aligned Pyramid Network for Dense Image Prediction</papertitle>
                </a>
                <br>
                <a href="http://www.shihuahuang.cn/">Shihua Huang</a>,
                <strong> Zhichao Lu </strong>,
                <a href="https://chengran.tech/">Ran Cheng</a>,
                <a href="https://www.chenghehust.com/">Cheng He</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp
                <br>
<!--                <a href="http://">project page</a>-->
<!--                /-->
                <a href="https://arxiv.org/abs/2108.07058">arXiv</a>
                /
<!--                <a href="https://">video</a>-->
<!--                /-->
                <a href="https://github.com/EMI-Group/FaPN">code</a>
                <p></p>
                <p>FaPN a simple yet effective top-down pyramidal architecture to generate multi-scale
                  features for dense image prediction. It improves FPN's AP / mIoU by 1.5 - 2.6% on
                  all tasks.</p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="pdvc_stop()" onmouseover="pdvc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/2021-iccv-pdvc.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2108.07781">
                <papertitle>End-to-End Dense Video Captioning with Parallel Decoding</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=TqY98koAAAAJ">Teng Wang</a>,
              <a href="http://zhangruimao.site/">Ruimao Zhang</a>,
              <strong> Zhichao Lu </strong>,
              <a href="https://scholar.google.com/citations?user=PcmyXHMAAAAJ">Feng Zheng</a>,
              <a href="https://chengran.tech/">Ran Cheng</a>,
              <a href="http://luoping.me/">Ping Luo</a>
              <br>
              <em>ICCV</em>, 2021 &nbsp
              <br>
<!--              <a href="http://">project page</a>-->
<!--              /-->
              <a href="https://arxiv.org/abs/2108.07781">arXiv</a>
              /
<!--              <a href="https://">video</a>-->
<!--              /-->
              <a href="https://github.com/ttengwang/PDVC">code</a>
              <p></p>
              <p>A transformer-based framework for end-to-end dense video captioning with parallel decoding.</p>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nat_stop()" onmouseover="nat_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/2021-tpami-nat.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2005.05859">
                <papertitle>Neural Architecture Transfer</papertitle>
              </a>
              <br>
              <strong> Zhichao Lu </strong>,
              <a href="http://hal.cse.msu.edu/team/gautam-sreekumar/">Gautam Sreekumar</a>,
              <a href="https://www.egr.msu.edu/~goodman/">Erik Goodman</a>,
              <a href="http://www.cse.msu.edu/~banzhafw/">Wolfgang Banzhaf</a>,
              <a href="https://egr.msu.edu/~kdeb">Kalyanmoy Deb</a>,
              <a href="http://hal.cse.msu.edu/">Vishnu N. Boddeti</a>
              <br>
              <em>TPAMI</em>, 2021 &nbsp
              <br>
<!--              <a href="http://">project page</a>-->
<!--              /-->
              <a href="https://arxiv.org/abs/2005.05859">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=8kY6pi9mHko">video</a>
              /
              <a href="https://github.com/human-analysis/neural-architecture-transfer">code</a>
              <p></p>
              <p>Improve practical utilities of neural architecture search through
                many-objective optimization, iterative surrogate modeling, and transfer learning.</p>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nsganetv2_stop()" onmouseover="nsganetv2_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/2020-eccv-nsganetv2.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2007.10396">
                <papertitle>NSGANetV2: Evolutionary Multi-Objective
                  Surrogate-Assisted Neural Architecture Search</papertitle>
              </a>
              <br>
              <strong> Zhichao Lu </strong>,
              <a href="https://egr.msu.edu/~kdeb">Kalyanmoy Deb</a>,
              <a href="https://www.egr.msu.edu/~goodman/">Erik Goodman</a>,
              <a href="http://www.cse.msu.edu/~banzhafw/">Wolfgang Banzhaf</a>,
              <a href="http://hal.cse.msu.edu/">Vishnu N. Boddeti</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="mediumvioletred"><strong>(Oral Presentation)</strong></font>
              <br>
<!--              <a href="http://">project page</a>-->
<!--              /-->
              <a href="https://arxiv.org/abs/2007.10396">arXiv</a>
              /
              <a href="https://www.bilibili.com/video/BV1Kb4y1C73T?from=search&seid=4025396091756306665">video</a>
              /
              <a href="https://github.com/mikelzc1990/nsganetv2">code</a>
              <p></p>
              <p>An efficient multi-objective neural architecture search framework.
                It can  be easily integrated with most of search spaces. </p>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="muxconv_stop()" onmouseover="muxconv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/2020-cvpr-muxconv.png' width="130">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2003.13880">
                <papertitle>MUXConv: Information Multiplexing in Convolutional
                  Neural Networks</papertitle>
              </a>
              <br>
              <strong> Zhichao Lu </strong>,
              <a href="https://egr.msu.edu/~kdeb">Kalyanmoy Deb</a>,
              <a href="http://hal.cse.msu.edu/">Vishnu N. Boddeti</a>
              <br>
              <em>CVPR</em>, 2020 &nbsp
              <br>
<!--              <a href="http://">project page</a>-->
<!--              /-->
              <a href="https://arxiv.org/abs/2003.13880">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=viFcGS1anO8">video</a>
              /
              <a href="https://github.com/human-analysis/MUXConv">code</a>
              <p></p>
              <p>A novel convolutional layer designed through neural architecture search to improve
                both parameter and FLOPs efficiency. </p>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
          margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nsganet_stop()" onmouseover="nsganet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div>
                <img src='images/2019-gecco-nsganet.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1810.03522">
                <papertitle>NSGA-Net: Neural Architecture Search
                  using Multi-Objective Genetic Algorithm</papertitle>
              </a>
              <br>
              <strong> Zhichao Lu </strong>,
              <a href="https://www.linkedin.com/in/whalenian">Ian Whalen</a>,
              <a href="http://hal.cse.msu.edu/">Vishnu N. Boddeti</a>,
              <a href="https://www.linkedin.com/in/yashesh-dhebar-500ab538/">Yashesh Dhebar</a>,
              <a href="https://egr.msu.edu/~kdeb">Kalyanmoy Deb</a>,
              <a href="https://www.egr.msu.edu/~goodman/">Erik Goodman</a>,
              <a href="http://www.cse.msu.edu/~banzhafw/">Wolfgang Banzhaf</a>
              <br>
              <em>GECCO</em>, 2019 &nbsp <font color="mediumvioletred"><strong>(Oral Presentation,
              Best Paper Award)</strong></font>
              <br>
<!--              <a href="http://">project page</a>-->
<!--              /-->
              <a href="https://arxiv.org/abs/1810.03522">arXiv</a>
              /
              <a href="https://www.ijcai.org/proceedings/2020/video/25520">video</a>
              /
              <a href="https://github.com/ianwhale/nsga-net">code</a>
              /
              <a href="https://www.ijcai.org/proceedings/2020/659">extended abstract
                (invited by IJCAI '20)</a>
              <p></p>
              <p>An evolutionary multi-objective search algorithm for evolving
                DNN architectures automatically. </p>
            </td>
          </tr>
          </tbody></table>

        </div>
      </div>
    </div>

    <footer class="footer mt-auto py-3 my-footer">
      <div class="container">
        <span class="text-muted">
          © Copyright 2021, Zhichao Lu, Southern University of Science and Technology.
        </span>
      </div>
    </footer>


    <!-- Bootstrap core JavaScript -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
      integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
      crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
      integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
      crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
      integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
      crossorigin="anonymous"></script>

    <script src="index.js"></script>

  </div>

</body>

</html>